# ðŸ”’ consec â€” LLM-Powered Container Security Assistant

**consec** enhances [Trivy](https://trivy.dev/) container vulnerability scans with **RAG** (Retrieval-Augmented Generation) and **local LLMs** for natural-language explanations, remediations, and context-aware Dockerfile advice.

> Zero-cost â€¢ Offline-capable â€¢ Privacy-first

![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue)
![License: MIT](https://img.shields.io/badge/license-MIT-green)

---

## Architecture

```
Trivy JSON â”€â”€â–º consec parse â”€â”€â–º Parsed CVEs â”€â”€â–º ChromaDB (Vector Store)
                                                      â”‚
User Query â”€â”€â–º consec query â”€â”€â–º Retrieve top-k docs â”€â”€â”¤
                                                      â–¼
                                              LangChain RAG Chain
                                                      â”‚
                              Dockerfile context â”€â”€â”€â”€â”€â”€â”¤
                                                      â–¼
                                              Ollama (Local LLM)
                                                      â”‚
                                                      â–¼
                                          Natural Language Response
```

## Quick Start

### Prerequisites

- **Python 3.10+**
- **[Ollama](https://ollama.ai/download)** â€” for local LLM inference
- **[Trivy](https://aquasecurity.github.io/trivy/)** â€” for container scanning (optional, can use existing JSON)
- **Docker** â€” for scanning images (optional)

### Installation

```bash
# Clone the repository
git clone https://github.com/Vrohs/consec.git
cd consec

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e ".[dev]"

# Pull an LLM model
ollama pull llama3.1:8b
```

### Usage

```bash
# Scan a Docker image
consec scan nginx:latest

# Parse an existing Trivy JSON file
consec parse data/sample_scans/nginx_scan.json

# Ingest scan data into the vector database
consec ingest data/sample_scans/nginx_scan.json

# Ask about a specific CVE
consec query "Explain CVE-2024-6119 and how to fix it"

# Interactive Q&A mode
consec query --interactive "What are the most critical vulnerabilities?"

# Review a Dockerfile for security issues
consec review Dockerfile --scan data/sample_scans/nginx_scan.json
```

### Configuration

| Environment Variable | Default | Description |
|---|---|---|
| `CONSEC_HOME` | `~/.consec` | Data directory |
| `CONSEC_MODEL` | `llama3.1:8b` | Default Ollama model |
| `OLLAMA_BASE_URL` | `http://localhost:11434` | Ollama server URL |

## Development

```bash
# Run tests (excluding tests that need Ollama)
pytest tests/ -v -m "not requires_ollama"

# Run all tests (requires Ollama running)
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=consec --cov-report=term-missing

# Lint
ruff check consec/ tests/
```

## Project Structure

```
consec/
â”œâ”€â”€ consec/             # Main package
â”‚   â”œâ”€â”€ cli.py          # Typer CLI commands
â”‚   â”œâ”€â”€ models.py       # Pydantic data models (Trivy schema)
â”‚   â”œâ”€â”€ parser.py       # Trivy JSON & Dockerfile parser
â”‚   â”œâ”€â”€ vectordb.py     # ChromaDB vector store
â”‚   â”œâ”€â”€ embeddings.py   # Sentence-transformer embeddings
â”‚   â”œâ”€â”€ llm.py          # Ollama LLM integration
â”‚   â”œâ”€â”€ prompts.py      # LangChain prompt templates
â”‚   â”œâ”€â”€ rag.py          # RAG chain orchestration
â”‚   â””â”€â”€ utils.py        # Display helpers & config
â”œâ”€â”€ data/sample_scans/  # Sample Trivy JSON outputs
â”œâ”€â”€ tests/              # Comprehensive test suite
â”œâ”€â”€ pyproject.toml      # Project configuration
â””â”€â”€ requirements.txt    # Dependencies
```

## License

MIT â€” see [LICENSE](LICENSE).
